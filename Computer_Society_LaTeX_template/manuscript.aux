\relax 
\citation{lpca}
\citation{genovese2014nonparametric}
\citation{fefferman2018fitting}
\citation{ozertem2011locally}
\citation{zhai2024quadratic}
\citation{zhai2025subspace}
\citation{liu2010robust}
\citation{zhang2017low}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\citation{lpca}
\citation{kde}
\citation{msf}
\citation{mfit}
\citation{mls}
\citation{ozertem2011locally}
\citation{chen2025power}
\citation{lpca}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {I-A}}Related works}{2}{}\protected@file@percent }
\citation{zhai2025subspace}
\@writefile{toc}{\contentsline {section}{\numberline {II}SCQM and its formulations}{3}{}\protected@file@percent }
\newlabel{sec:model}{{II}{3}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Quadratic Fitting Model with Subspace Constraint}{3}{}\protected@file@percent }
\newlabel{eq:model_general}{{1}{3}{}{}{}}
\newlabel{eq:mle_general}{{2}{3}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {II-A}1}Quadratic Function Class}{3}{}\protected@file@percent }
\newlabel{eq:f_compact}{{3}{3}{}{}{}}
\newlabel{eq:f_theta}{{4}{3}{}{}{}}
\newlabel{eq:loss_general}{{5}{3}{}{}{}}
\newlabel{projection}{{6}{3}{}{}{}}
\citation{roenko2014estimation}
\citation{pascal2013parameter}
\citation{do2002wavelet}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Identifiability}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Loss functions}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Criteria for Choosing the Loss Function}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {II-D}0a}Known noise distribution}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {II-D}0b}Observable noise samples}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {II-D}0c}Unobservable noise embedded in observations.}{4}{}\protected@file@percent }
\citation{kotz2012laplace}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Common loss functions, together with their gradients and Hessians with respect to $x$, and the corresponding noise distributions under a maximum likelihood interpretation.}}{5}{}\protected@file@percent }
\newlabel{tab:loss_gradients}{{I}{5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-E}}A toy example in ${\mathbb  R}^2$}{5}{}\protected@file@percent }
\newlabel{toy}{{\mbox  {II-E}}{5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the fitted curves and projection points obtained using $\ell _p^p$ losses with different values of $p$.}}{5}{}\protected@file@percent }
\newlabel{fig:robustness2}{{1}{5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of the fitted curves and projection points obtained using $\ell _p^p$ losses with different values of $p$ when restricting the function class to be linear (${\cal  A} =\bf  0$).}}{5}{}\protected@file@percent }
\newlabel{fig:robustness2_3d}{{2}{5}{}{}{}}
\citation{strang2022introduction}
\@writefile{toc}{\contentsline {section}{\numberline {III}Gradients and KKT condition}{6}{}\protected@file@percent }
\newlabel{sec:gradients}{{III}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Gradient with respect to $\{\tau _k\}_{k=1}^n$}{6}{}\protected@file@percent }
\newlabel{1st_order}{{8}{6}{}{}{}}
\@writefile{thm}{\contentsline {corollary}{{Corollary}{1}{Matrix representation theorem}}{6}{}\protected@file@percent }
\newlabel{cor1}{{1}{6}{}{}{}}
\newlabel{grad_tau}{{9}{6}{}{}{}}
\citation{absil2008optimization}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Riemannian Gradient and First-Order Optimality Condition for $Q$}{7}{}\protected@file@percent }
\newlabel{retraction_QR}{{10}{7}{}{}{}}
\@writefile{thm}{\contentsline {proposition}{{Proposition}{1}{}}{7}{}\protected@file@percent }
\newlabel{prop:riemannian_stationary_Q}{{1}{7}{}{}{}}
\newlabel{first-order-Q}{{11}{7}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Gradient for $\Theta $ and $c$}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-C}0a}Gradient with respect to $\Theta $}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-C}0b}Gradient with respect to $c$}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-C}0c}KKT condition}{7}{}\protected@file@percent }
\newlabel{first-order-condition}{{12}{7}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Convexity Analysis}{8}{}\protected@file@percent }
\newlabel{sec:convexity}{{IV}{8}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {IV-}0a}Convexity of the Projection Problem}{8}{}\protected@file@percent }
\newlabel{eq:hess_tau}{{13}{8}{}{}{}}
\newlabel{hessian2}{{14}{8}{}{}{}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{1}{Local convexity radius for $\ell _p^p$-SCQM}}{8}{}\protected@file@percent }
\newlabel{thm:conv_radius_lp}{{1}{8}{}{}{}}
\citation{bhattacharya2012nonparametric}
\citation{krantz2013implicit}
\@writefile{toc}{\contentsline {section}{\numberline {V}Sensitivity analysis}{9}{}\protected@file@percent }
\newlabel{sec:sensitivity}{{V}{9}{}{}{}}
\@writefile{thm}{\contentsline {proposition}{{Proposition}{2}{Sensitivity of the Optimal Solution}}{9}{}\protected@file@percent }
\newlabel{prop:sensitivity_c}{{2}{9}{}{}{}}
\newlabel{c_optimal}{{15}{9}{}{}{}}
\newlabel{robust_result}{{16}{9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Robustness Interpretation}{9}{}\protected@file@percent }
\newlabel{ell2_delta_c}{{17}{9}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Algorithm}{9}{}\protected@file@percent }
\newlabel{Alg}{{VI}{9}{}{}{}}
\citation{absil2008optimization}
\citation{golub2013matrix}
\citation{nocedal2006numerical}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {VI-}0a}Orthonormal retraction via aligned QR}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {VI-}0b}Asynchronous learning-rate adjustment}{10}{}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Riemannian Gradient Descent for SCQM }}{10}{}\protected@file@percent }
\newlabel{alg:RGD_QMF_tight}{{1}{10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of the fitted curves and projection points obtained using $\ell _p^p$ losses with different values of $p$.}}{11}{}\protected@file@percent }
\newlabel{fig:robustness2_3d}{{3}{11}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {VI-}0c}Learning process}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}Numerical Experiments}{11}{}\protected@file@percent }
\newlabel{sec:experiments}{{VII}{11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Performance is compared across models and noise levels using boxplots of the squared reconstruction error, $\|\tilde  {x}_i - P(x_i)\|_2^2$, computed over all samples.}}{11}{}\protected@file@percent }
\newlabel{boxplots}{{4}{11}{}{}{}}
\newlabel{noisy_observation}{{18}{11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VII-A}}Simulation with Spherical Data in ${\mathbb  R}^3$}{11}{}\protected@file@percent }
\citation{lecun2002gradient}
\citation{zhai2025subspace}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Mean squared error (MSE) of different models under varying noise levels.}}{12}{}\protected@file@percent }
\newlabel{MSE_compare}{{II}{12}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of reconstruction methods under different loss functions and model settings. Each row displays 16 reconstructed images. From top to bottom, the rows correspond to the original images, linear model with $\ell _2$ loss, SCQM with $\ell _2$ loss, linear model with $\ell _p^p$ loss ($p=2$), SCQM with $\ell _p^p$ loss ($p=2$), linear model with $\ell _p^p$ loss ($p=1$), and SCQM with $\ell _p^p$ loss ($p=1$), respectively. }}{12}{}\protected@file@percent }
\newlabel{fig:sqmf_comparison}{{5}{12}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VII-B}}Performance on Real World Dataset}{12}{}\protected@file@percent }
\citation{wainwright2019high}
\bibstyle{unsrt}
\bibdata{sample}
\bibcite{lpca}{1}
\bibcite{genovese2014nonparametric}{2}
\bibcite{fefferman2018fitting}{3}
\bibcite{ozertem2011locally}{4}
\bibcite{zhai2024quadratic}{5}
\bibcite{zhai2025subspace}{6}
\bibcite{liu2010robust}{7}
\bibcite{zhang2017low}{8}
\bibcite{kde}{9}
\bibcite{msf}{10}
\bibcite{mfit}{11}
\bibcite{mls}{12}
\bibcite{chen2025power}{13}
\bibcite{roenko2014estimation}{14}
\bibcite{pascal2013parameter}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visualization of latent-space ($d=2$) interpolation for the linear model ($\Theta = \bf  0$) and the quadratic model ($\Theta \neq  \bf  0$), learned from data consisting of the three digits `2', `6', and `8'. }}{13}{}\protected@file@percent }
\newlabel{fig:interpolation}{{6}{13}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VII-C}}Interpolation via SCQM}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Conclusion}{13}{}\protected@file@percent }
\newlabel{sec:conclusion}{{VIII}{13}{}{}{}}
\@writefile{toc}{\contentsline {section}{References}{13}{}\protected@file@percent }
\bibcite{do2002wavelet}{16}
\bibcite{kotz2012laplace}{17}
\bibcite{strang2022introduction}{18}
\bibcite{absil2008optimization}{19}
\bibcite{bhattacharya2012nonparametric}{20}
\bibcite{krantz2013implicit}{21}
\bibcite{golub2013matrix}{22}
\bibcite{nocedal2006numerical}{23}
\bibcite{lecun2002gradient}{24}
\bibcite{wainwright2019high}{25}
\@writefile{thm}{\contentsline {proof}{{Proof}{1}{Proposition~\ref {prop:riemannian_stationary_Q}}}{14}{}\protected@file@percent }
\newlabel{optimal_Q}{{19}{14}{}{}{}}
\@writefile{thm}{\contentsline {proof}{{Proof}{2}{Theorem~\ref {thm:conv_radius_lp}}}{14}{}\protected@file@percent }
\@writefile{thm}{\contentsline {proof}{{Proof}{3}{Proposition~\ref {prop:sensitivity_c}}}{14}{}\protected@file@percent }
\newlabel{eq:stationary_c}{{20}{14}{}{}{}}
\newlabel{sen}{{21}{14}{}{}{}}
\newlabel{nablacc}{{22}{14}{}{}{}}
\newlabel{nablacx}{{23}{15}{}{}{}}
\gdef \@abspage@last{15}
